import os
import json
import subprocess
from datetime import datetime
from dotenv import load_dotenv
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import aiohttp  # ×œ×©×œ×™×—×ª × ×ª×•× ×™× ×œ-Zapier

# --- ×˜×¢×™× ×ª ××©×ª× ×™ ×¡×‘×™×‘×” ---
load_dotenv()

# --- ×§×‘×•×¢×™× ---
CHROMA_DIR = os.getenv("CHROMA_DB_DIR", "./data/index")
SUMMARY_FILE = os.path.join("data", "index_summary.json")
ZAPIER_WEBHOOK_URL = "https://hooks.zapier.com/hooks/catch/5499574/u5u0yfy/"

# --- ×”×’×“×¨×ª FastAPI ---
app = FastAPI(title="AI Shabaton API")

# --- ×”×’×“×¨×•×ª CORS ---
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ××¤×©×¨ ×œ×©×™× ["https://www.shabaton.online"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ×—×™×‘×•×¨ ×œ-OpenAI ---
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ×—×™×‘×•×¨ ×œ××¡×“ ×”× ×ª×•× ×™× ×©×œ Chroma ---
chroma_client = None
collection = None

if os.path.exists(CHROMA_DIR):
    try:
        chroma_client = chromadb.PersistentClient(path=CHROMA_DIR)
        ef = embedding_functions.OpenAIEmbeddingFunction(
            api_key=os.getenv("OPENAI_API_KEY"),
            model_name=os.getenv("EMBED_MODEL", "text-embedding-3-small")
        )
        collection = chroma_client.get_or_create_collection("shabaton_faq", embedding_function=ef)
        print(f"âœ… Connected to Chroma at {CHROMA_DIR}")
    except Exception as e:
        print(f"âš ï¸ Could not connect to Chroma: {e}")
else:
    print(f"âš ï¸ Chroma directory {CHROMA_DIR} not found.")


# --- ×¤×•× ×§×¦×™×” ×œ××™× ×“×•×§×¡ ××•×˜×•××˜×™ ---
def ensure_index_exists():
    """×× ××™×Ÿ ××™× ×“×§×¡ â€” ××¨×™×¥ indexer.py ×•×‘×•× ×” ××—×“ ×—×“×©."""
    if os.path.exists(SUMMARY_FILE):
        print("âœ… Found existing index_summary.json â€” skipping rebuild.")
        return

    print("âš™ï¸ No index found â€” running indexer.py to build a new one...")
    try:
        result = subprocess.run(
            ["python", "indexer.py"],
            capture_output=True,
            text=True,
            timeout=300
        )
        print("ğŸ“œ --- indexer.py output ---")
        print(result.stdout)
        print(result.stderr)
        print("ğŸ“œ -------------------------")

        if os.path.exists(SUMMARY_FILE):
            print("âœ… Index successfully created!")
        else:
            print("âš ï¸ index_summary.json not found after indexing.")
    except Exception as e:
        print(f"âŒ Failed to run indexer.py: {e}")


# --- × ×•×•×“× ×©×”××™× ×“×§×¡ × ×‘× ×” ×›×©×©×¨×ª ×¢×•×œ×” ---
ensure_index_exists()


# --- × ×§×•×“×ª ×‘×“×™×§×” ×¨××©×™×ª ---
@app.get("/")
def root():
    return {
        "message": "âœ… Shabaton API is running",
        "docs": "/docs",
        "index_summary": "/index-summary",
        "indexed_pages": "/indexed-pages",
        "chroma_status": "/chroma-status"
    }


# --- × ×§×•×“×ª ×§×¦×” ×¨××©×™×ª ×œ×©××œ×•×ª ××”××ª×¨ ---
@app.post("/query")
async def query(request: Request):
    """××§×‘×œ ×©××œ×” ××”××ª×¨, ××—×¤×© ×‘××™×“×¢ ×”×××•× ×“×§×¡, ×•×× ××™×Ÿ ×ª×•×¦××” â€” ×¢×•× ×” ×ª×©×•×‘×ª fallback."""
    data = await request.json()
    question = data.get("query", "").strip()

    if not question:
        return {"answer": "×œ× ×”×ª×§×‘×œ×” ×©××œ×”.", "sources": []}

    # ğŸ” ×—×™×¤×•×© ×‘×××’×¨ Chroma
    answer_text = None
    sources = []

    if collection:
        try:
            results = collection.query(
                query_texts=[question],
                n_results=3
            )

            if results and results.get("documents") and results["documents"][0]:
                top_docs = results["documents"][0]
                sources = [m["source"] for m in results["metadatas"][0] if "source" in m]

                context = "\n\n".join(top_docs)
                completion = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "××ª×” ×¢×•×–×¨ ×—×›× ×©××‘×•×¡×¡ ×¨×§ ×¢×œ ××™×“×¢ ××ª×•×š ××ª×¨ ×©×‘×ª×•×Ÿ."},
                        {"role": "user", "content": f"×©××œ×”: {question}\n\n××™×“×¢ ×¨×œ×•×•× ×˜×™ ××”××ª×¨:\n{context}"}
                    ]
                )
                answer_text = completion.choices[0].message.content.strip()

        except Exception as e:
            print(f"âš ï¸ Error querying Chroma: {e}")

    # ×× ×œ× × ××¦××• ×ª×•×¦××•×ª â€” ×ª×©×•×‘×ª fallback
    if not answer_text:
        answer_text = "×œ× × ××¦× ××™×“×¢ ×¨×œ×•×•× ×˜×™, ××•×–×× ×™× ×œ×¤× ×•×ª ×œ×¦×•×•×ª ×©×‘×ª×•×Ÿ ×‘××™×™×œ info@shabaton.co.il"
        sources = []

    # ğŸ“¤ ×©×œ×™×—×ª ×”×©××œ×” ×•×”×ª×©×•×‘×” ×œ-Zapier
    try:
        async with aiohttp.ClientSession() as session:
            await session.post(
                ZAPIER_WEBHOOK_URL,
                json={
                    "timestamp": datetime.utcnow().isoformat(),
                    "question": question,
                    "answer": answer_text,
                    "sources": sources,
                    "page": request.headers.get("Referer", "Unknown"),
                    "ip": request.client.host if request.client else "Unknown"
                }
            )
        print("ğŸ“¨ Sent to Zapier")
    except Exception as e:
        print(f"âš ï¸ Failed to send to Zapier: {e}")

    return {"answer": answer_text, "sources": sources}


# --- ×ª×§×¦×™×¨ ×”××™× ×“×•×§×¡ ---
@app.get("/index-summary")
def get_index_summary():
    if not os.path.exists(SUMMARY_FILE):
        return {"status": "not_found", "message": "index_summary.json not found yet."}

    with open(SUMMARY_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    return {
        "status": "ok",
        "files_indexed": len(data.get("files", [])),
        "total_chunks": data.get("total_chunks", 0),
        "details": data.get("files", [])
    }


# --- ×¨×©×™××ª ×”×“×¤×™× ×”×××•× ×“×§×¡×™× ---
@app.get("/indexed-pages")
def get_indexed_pages():
    if not os.path.exists(SUMMARY_FILE):
        return {"status": "not_found", "message": "No index summary found."}

    with open(SUMMARY_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    pages = [item["source"] for item in data.get("files", [])]
    return {
        "status": "ok",
        "total_pages": len(pages),
        "pages": pages
    }


# --- ×‘×“×™×§×ª ××¦×‘ ×—×™×‘×•×¨ ×œ××¡×“ ×”× ×ª×•× ×™× ---
@app.get("/chroma-status")
def chroma_status():
    if not os.path.exists(CHROMA_DIR):
        return {"status": "not_found", "message": f"Chroma directory not found: {CHROMA_DIR}"}
    try:
        client = chromadb.PersistentClient(path=CHROMA_DIR)
        collections = client.list_collections()
        return {"status": "ok", "collections": [c.name for c in collections]}
    except Exception as e:
        return {"status": "error", "message": str(e)}
